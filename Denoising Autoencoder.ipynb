{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noise_factor = 0.1\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def display(array1, array2):\n",
    "    \"\"\"\n",
    "    Displays ten random images from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 10\n",
    "\n",
    "    indices = np.random.randint(len(array1), size=n)\n",
    "    images1 = array1[indices, :]\n",
    "    images2 = array2[indices, :]\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(image1.reshape(256, 256))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(image2.reshape(256, 256))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from PIL import ImageFile\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5579e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob        \n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from numpy import reshape\n",
    "\n",
    "\n",
    "train_filenames = glob('/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/*.jpeg')\n",
    "test_filenames = glob('/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA/*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "\n",
    "for each in tqdm(train_filenames):\n",
    "    each = io.imread(each)\n",
    "    each = resize(each, (256, 256), anti_aliasing=True)\n",
    "    train.append(each)\n",
    "    \n",
    "for each in tqdm(test_filenames):\n",
    "    each = io.imread(each)\n",
    "    each = resize(each, (256, 256), anti_aliasing=True)\n",
    "    test.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.expand_dims(train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f24fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = xtrain[:1000]\n",
    "valid_data = xtrain[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f30252",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "input = layers.Input(shape=(256, 256, 1))\n",
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# Decoder\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(input, x)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet model: https://www.kaggle.com/advaitsave/tensorflow-2-nuclei-segmentation-unet\n",
    "# Any UNET implementation will work. I chose this one because it written using simple logics. \n",
    "\n",
    "\n",
    "inputs = Input((256, 256, 1))\n",
    "\n",
    "\n",
    "c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "c1 = BatchNormalization()(c1)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "c1 = BatchNormalization()(c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = BatchNormalization()(c2)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "c2 = BatchNormalization()(c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = BatchNormalization()(c3)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "c3 = BatchNormalization()(c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = BatchNormalization()(c4)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "c4 = BatchNormalization()(c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = BatchNormalization()(c5)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "c5 = BatchNormalization()(c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = BatchNormalization()(c6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "c6 = BatchNormalization()(c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = BatchNormalization()(c7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "c7 = BatchNormalization()(c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = BatchNormalization()(c8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "c8 = BatchNormalization()(c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = BatchNormalization()(c9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "c9 = BatchNormalization()(c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55896fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre training\n",
    "\n",
    "model.fit(\n",
    "    x=train_data,\n",
    "    y=train_data,\n",
    "    epochs=200,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    validation_data=(valid_data, valid_data),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bf65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_data = noise(train_data)\n",
    "noisy_valid_data = noise(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=noisy_train_data,\n",
    "    y=train_data,\n",
    "    epochs=100,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    validation_data=(noisy_valid_data, valid_data),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(noisy_valid_data)\n",
    "#display(noisy_test_data, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad376ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(predictions[157])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(noisy_valid_data[157])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(valid_data[157])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0269468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "ssimArr = []\n",
    "\n",
    "for idx, each in enumerate(predictions):\n",
    "    ssimArr.append(ssim(each, valid_data[idx], data_range=1.0 - 0.0, multichannel=True))\n",
    "\n",
    "np.mean(ssimArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b36599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
